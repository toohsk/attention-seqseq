{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib\n",
    "import MeCab\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data/jawiki-latest-docs.xml', 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DOCS_TAB = ('<docs>', '</docs>')\n",
    "\n",
    "page_id_tab_pattern = re.compile(r'<doc\\sid=\"(?P<id>[0-9]+)\"\\surl=\"(?P<url>.+?)\"\\stitle=\"(?P<title>.+?)\">')\n",
    "page_end_tab_pattern = re.compile(r'</doc>')\n",
    "a_tab_pattern = re.compile(r'<a\\shref=\"(?P<entity>.+?)\">(?P<anchor_text>.+?)</a>')\n",
    "ref_tab_pattern = re.compile(r'<ref.+?</ref>')\n",
    "\n",
    "tagger = MeCab.Tagger('-d /usr/local/Cellar/mecab/0.996/lib/mecab/dic/mecab-ipadic-neologd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tokens(line):\n",
    "    token_list = []\n",
    "    node = tagger.parseToNode(line)\n",
    "    while node:\n",
    "        token_list.append(node.surface)\n",
    "        node = node.next\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_empty_char(words):\n",
    "    while words.count(\"\") > 0:\n",
    "        words.remove(\"\")\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_list_data(list_data, file_name):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(list_data.encode('utf-8'), f)\n",
    "        \n",
    "# save_list_data(all_src, 'src_list.pickle')\n",
    "# save_list_data(all_dest, 'replace_entity_list.pickle')\n",
    "# save_list_data(all_only_entity, 'entity_list.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page_entity_dic = {}\n",
    "skip_flag = False\n",
    "\n",
    "all_src, all_dest, all_only_entity = [], [], []\n",
    "src, dest, only_entity = [], [], []\n",
    "\n",
    "NIL = '<nil>'\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    if i % 10000 == 0:\n",
    "        print(datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\"), 'Executing: {0}...'.format(i))\n",
    "    if i != 0 and i % 10000 == 0:\n",
    "        idx = int(i / 10000)\n",
    "#         print(all_src)\n",
    "        save_list_data('\\n'.join(all_src), './data/seq2seq_wiki/src/src_list_{0}.pickle'.format(idx))\n",
    "        save_list_data('\\n'.join(all_dest), './data/seq2seq_wiki/dest_all/replace_entity_list_{0}.pickle'.format(idx))\n",
    "        save_list_data('\\n'.join(all_only_entity), './data/seq2seq_wiki/dest_entity/entity_list_with_nil_{0}.pickle'.format(idx))\n",
    "        all_src, all_dest, all_only_entity = [], [], []\n",
    "    \n",
    "    line = line.replace('\\n', '')\n",
    "    if line in DOCS_TAB:\n",
    "        continue\n",
    "    \n",
    "    if page_end_tab_pattern.match(line):\n",
    "#         print(page_title, \"end\")\n",
    "#         print(\"Dictionary:\", page_entity_dic)\n",
    "        page_entity_dic = {}\n",
    "        src, dest, only_entity = [], [], []\n",
    "        continue\n",
    "        \n",
    "#     if ref_tab_pattern.match(line):\n",
    "#         print(line)\n",
    "#         print(ref_tab_pattern.sub(line, \"\"))\n",
    "#         break\n",
    "    \n",
    "    page_id_match_obj = page_id_tab_pattern.search(line)\n",
    "    if page_id_match_obj:\n",
    "        page_title = page_id_match_obj.group('title')\n",
    "        page_entity_dic[page_title] = page_title\n",
    "    \n",
    "    linked_line_match_obj = a_tab_pattern.findall(line)\n",
    "    if linked_line_match_obj:\n",
    "        for match_obj in linked_line_match_obj:\n",
    "            entity = match_obj[0]\n",
    "            anchor_text = match_obj[1]\n",
    "            if entity.startswith(\"http\"): continue\n",
    "            page_entity_dic[anchor_text] = entity\n",
    "    \n",
    "    splited_line_match_obj = a_tab_pattern.split(line)\n",
    "    if len(splited_line_match_obj) > 2:\n",
    "        src, dest, only_entity = [], [], []\n",
    "        for idx in range(0, len(splited_line_match_obj)):\n",
    "            if splited_line_match_obj[idx] == \"\" or skip_flag:\n",
    "                skip_flag = False\n",
    "                continue\n",
    "                \n",
    "#             print(splited_line_match_obj[idx])\n",
    "#             if splited_line_match_obj[idx].startswith(\"%\") and (idx+1) <  len(splited_line_match_obj):\n",
    "            current_token = splited_line_match_obj[idx]\n",
    "            if current_token.startswith(\"%\") and urllib.parse.unquote(current_token) != current_token:\n",
    "                try:\n",
    "                    encoded_token = splited_line_match_obj[idx+1]\n",
    "                    src.append(encoded_token)\n",
    "                    dest.append('['+urllib.parse.unquote(encoded_token)+']')\n",
    "                    only_entity.append(urllib.parse.unquote(encoded_token))\n",
    "                    skip_flag = True\n",
    "                except Exception as e:\n",
    "                    print(current_token)\n",
    "                    print(splited_line_match_obj[idx+1])\n",
    "            else:\n",
    "                nouns = get_tokens( splited_line_match_obj[idx])\n",
    "                src.extend(nouns)\n",
    "                dest.extend(nouns)\n",
    "                only_entity.extend([NIL for i in nouns])\n",
    "        \n",
    "        src = remove_empty_char(src)\n",
    "        dest = remove_empty_char(dest)\n",
    "        only_entity = remove_empty_char(only_entity)\n",
    "\n",
    "#         print(src) \n",
    "#         print(dest)\n",
    "#         print(only_entity)\n",
    "#         print(\"Size src: {}, dest: {}\".format(len(src), len(dest)))\n",
    "        \n",
    "        all_src.append(' '.join(src))\n",
    "        all_dest.append(' '.join(dest))\n",
    "        all_only_entity.append(' '.join(only_entity))\n",
    "#     if i>100:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(all_src) \n",
    "# print(all_dest)\n",
    "# print(all_only_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}